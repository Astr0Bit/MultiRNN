{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multirnn import MultiRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MultiRNN in module multirnn:\n",
      "\n",
      "class MultiRNN(builtins.object)\n",
      " |  MultiRNN(dataset, train, test, length, LSTM_units, activation, optimizer, batch_size, epochs)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dataset, train, test, length, LSTM_units, activation, optimizer, batch_size, epochs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      dataset : pandas.DataFrame\n",
      " |          A pandas DataFrame containing all data,\n",
      " |          will be used to check that data is ready.\n",
      " |      \n",
      " |      train : pandas.DataFrame\n",
      " |          A valid training pandas dataframe\n",
      " |          of original dataset having index as orginal dataset.\n",
      " |      \n",
      " |      test : str\n",
      " |          A valid testing part of original dataset\n",
      " |          having index as original data index.\n",
      " |      \n",
      " |      length : int > 0\n",
      " |          Positive int, length of the output sequences.\n",
      " |      \n",
      " |      LSTM_units : int > 0 | list of int > 0\n",
      " |          Positive int, for cells in LSTM of keras or PyTorch\n",
      " |          or list of positive ints for each feature LSTM\n",
      " |          cells needed for this feature that matches the index.\n",
      " |      \n",
      " |      activation : str | list of str, default = \"tanh\"\n",
      " |          A valid activation function for RNN LSTM layer,\n",
      " |          or list of activation functions for each feature.\n",
      " |          Options [\"tanh\", \"sigmoid\", \"softmax\", \"relu\"]\n",
      " |      \n",
      " |      optimizer : str | list of str, default = \"adam\"\n",
      " |          A valid optimizer for the output layer,\n",
      " |          or list of optimizers for each feature.\n",
      " |          Options [\"adam\", \"rmsprop\", \"sgd\"]\n",
      " |      \n",
      " |      batch_size : int > 0, default = 1\n",
      " |          Number of time series samples in each batch\n",
      " |          (except maybe the last one).\n",
      " |      \n",
      " |      epochs : int > 0 | list of int, default = 25 per feature\n",
      " |          Number of epochs to train the model.\n",
      " |          Could either be a single int or list of ints.\n",
      " |      \n",
      " |      NOTE : __init__ should run generate_model_list_per_column_in_dataset()\n",
      " |      and parse parameters to it. As we do not parse parameter \"dataset\" to __init__,\n",
      " |      my guess is that method \"ready_for_processing()\" should be a @staticmethod as \n",
      " |      parameter \"dataset\" is user-defined and outside of the class.\n",
      " |      Ask Ammar about parameter \"test\" as it is a string, should it be a pandas DataFrame?\n",
      " |  \n",
      " |  build_model_per_column(self, train, test, length, LSTM_units, activation, optimizer, batch_size, epochs)\n",
      " |      Method that takes inputs and creates RNN LSTM for\n",
      " |      the generated single column dataset, based on other\n",
      " |      parameters provided. This method will do needed\n",
      " |      scaling, generating time series and build the\n",
      " |      RNN LSTM Keras / PyTorch model based on hyper \n",
      " |      parameters with early stopping based on val_loss and\n",
      " |      patience of max 2 epochs.\n",
      " |      \n",
      " |      Optional: save losses dataframe as a csv-file to local folder.\n",
      " |      Optional: save model as Keras / PyTorch with .h5\n",
      " |      \n",
      " |      This method should also evaluate the model, it creates\n",
      " |      the model predictions of the part of train data equal\n",
      " |      to or shorter than test dataset length, and save it as\n",
      " |      DataFrame with original index in test values in order\n",
      " |      to plot both of them.\n",
      " |      \n",
      " |      Returns model, losses, and related model name.\n",
      " |      \n",
      " |      NOTE to self: check with Ammar to make sure\n",
      " |      we have understood this method correctly.\n",
      " |  \n",
      " |  generate_dataset_per_column_with_original_index(self, dataset)\n",
      " |      Method that will generate datasets as descibed in C. (check PDF)\n",
      " |      \n",
      " |      C. Build RNN LSTM model for each generated dataset, so if \n",
      " |      we have for example 100 features, we shall train 100 \n",
      " |      models over generated train dataset and validate using \n",
      " |      generated train dataset.\n",
      " |      \n",
      " |      Optional: can save them to local folder for later use.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : pandas.DataFrame\n",
      " |          A valid pandas DataFrame.\n",
      " |  \n",
      " |  generate_model_list_per_column_in_dataset(self, train, test, length, LSTM_units, activation, optimizer, batch_size, epochs)\n",
      " |      Method that creates list of models for each column.\n",
      " |      It starts by calling generate_dataset_per_column_with_original_index()\n",
      " |      on both train and test pandas DataFrames, then sens them into build_model_per_column()\n",
      " |      method in order to get output of Keras / PyTorch models, losses DataFrame and model name.\n",
      " |      These will be run on each column in train dataset and collected into dictionary that has\n",
      " |      key as column name, and values is a dictionary that contains model, losses, and model name.\n",
      " |      (it is a dictionary of dictionaries)\n",
      " |      \n",
      " |      Returns the dictionary containing all columns.\n",
      " |      \n",
      " |      TIP: Constructor will call this method.\n",
      " |  \n",
      " |  plot_loss_val_loss_per_column(self, column, figure_width, figure_height, save_plot_name)\n",
      " |      Method to plot loss against val_loss \n",
      " |      of input column and save it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str\n",
      " |          A valid column name in the original dataset.\n",
      " |      \n",
      " |      figure_width : int > 0\n",
      " |          Positive int, width of the plot.\n",
      " |      \n",
      " |      figure_height : int > 0\n",
      " |          Positive int, height of the plot.\n",
      " |      \n",
      " |      save_plot_name : str, default=\"plot_loss_val_loss_\"\n",
      " |          Name of the plot to be saved.\n",
      " |  \n",
      " |  plot_predict_against_test_dataset_per_column(self, column, figure_width, figure_height, save_plot_name)\n",
      " |      Method to plot the real test values and predicted values on the same plot\n",
      " |      using plot dimensions mentioned and column name. And save the plots.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str\n",
      " |          A valid column name in the original dataset.\n",
      " |      \n",
      " |      figure_width : int > 0\n",
      " |          Positive int, width of the plot.\n",
      " |      \n",
      " |      figure_height : int > 0\n",
      " |          Positive int, height of the plot.\n",
      " |      \n",
      " |      save_plot_name : str, default=\"plot_test_vs_predict_\"\n",
      " |          Name of the plot to be saved.\n",
      " |  \n",
      " |  predict(self, datarow)\n",
      " |      Method to generate prediction for all features\n",
      " |      and input dataframe that has columns matching\n",
      " |      the original dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      datarow : pandas.DataFrame\n",
      " |          A valid pandas DataFrame that has columns\n",
      " |          matching the original dataset.\n",
      " |      \n",
      " |      Returns prediction as a pandas DataFrame\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  ready_for_processing(dataset)\n",
      " |      Static method to check if the dataset is ready to process.\n",
      " |      Checks NaN values, and if the dataset is a pandas DataFrame etc.\n",
      " |      \n",
      " |      NOTE to self: take inspiration from AutoEDA from ML-APP\n",
      " |      (https://github.com/Astr0Bit/ML_APP, or check folder \"from ML_APP/auto_eda.py\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : pandas.DataFrame\n",
      " |          A valid pandas DataFrame.\n",
      " |      \n",
      " |      Returns True if ready, False if not.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MultiRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data is NOT ready. Please fix before proceeding.\nErrors found : {'missing_values': 41, 'duplicates': None, 'outliers': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/diabetes_na_2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m multi \u001b[38;5;241m=\u001b[39m \u001b[43mMultiRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLSTM_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Programmering\\Python\\Exams\\Deep Learning Exam - 18-05-2024\\multirnn.py:62\u001b[0m, in \u001b[0;36mMultiRNN.__init__\u001b[1;34m(self, dataset, train, test, length, LSTM_units, activation, optimizer, batch_size, epochs)\u001b[0m\n\u001b[0;32m     60\u001b[0m ready_, errors \u001b[38;5;241m=\u001b[39m MultiRNN\u001b[38;5;241m.\u001b[39mready_for_processing(dataset) \u001b[38;5;66;03m# check if data is ready\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ready_:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData is NOT ready. Please fix before proceeding.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m     63\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErrors found : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData is ready --> Proceeding\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "\u001b[1;31mValueError\u001b[0m: Data is NOT ready. Please fix before proceeding.\nErrors found : {'missing_values': 41, 'duplicates': None, 'outliers': None}"
     ]
    }
   ],
   "source": [
    "# testing ready_for_processing method\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/diabetes_na_2.csv')\n",
    "multi = MultiRNN(dataset=df, test=None, train=None,\n",
    "                 length=None, LSTM_units=None, activation=None,\n",
    "                 optimizer=None, batch_size=None, epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
